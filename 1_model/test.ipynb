{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import model\n",
    "from model import MyDataSet\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "\n",
    "from model import MyDataSet,generate_process,process2\n",
    "import model\n",
    "import matplotlib.pyplot as plt\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成和测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "save_path3   = 'result/last_result_16/'\n",
    "pic_path     = 'result/test_pic/'\n",
    "\n",
    "noise_dim  = 16\n",
    "mesh2num   = 16\n",
    "BATCH_SIZE = 128\n",
    "batch_size = BATCH_SIZE\n",
    "ffd_dim    = (3,7,1)\n",
    "point_num  = (ffd_dim[0]+1)*(ffd_dim[1]+1)*(ffd_dim[2]+1)\n",
    "dim_mesh   = (18,68,3)\n",
    "upper_vdim = 64\n",
    "lower_vdim = 11\n",
    "device     = 'cpu'\n",
    "mesh2num_model = model.ConvNet(mesh2num).to(device) \n",
    "G = model.DeepConvNet3(noise_dim + mesh2num,point_num,upper_vdim).to(device)\n",
    "D = model.DeepConvNet2(batch_size,1).to(device) #输出为1维向量\n",
    "    \n",
    "mesh2num_model.load_state_dict(torch.load(save_path3 +\"m2n_param.pkl\"))\n",
    "G.load_state_dict(torch.load(save_path3 +\"generator_param.pkl\"))\n",
    "D.load_state_dict(torch.load(save_path3 +\"discriminator_param.pkl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root   = 'F:\\\\graduate_student\\\\T2_GANpropeller\\\\test2\\\\1_model\\\\grid_mesh\\\\'\n",
    "\n",
    "base_meshs = np.load(data_root + 'mesh_data_test.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base max c: 0.1990192041774946 max beta: 22.22549356306708\n",
      "0 max c: 0.19385693190249775 max beta: 30.22238534138534\n",
      "1 max c: 0.17711801413569855 max beta: 31.1187878165556\n",
      "2 max c: 0.19628152364902304 max beta: 20.333006280361978\n",
      "3 max c: 0.19901136772172442 max beta: 32.24126494416325\n",
      "4 max c: 0.1886738114738666 max beta: 39.10379230941474\n",
      "5 max c: 0.18728862898858525 max beta: 23.427760332384146\n",
      "6 max c: 0.17831271891305217 max beta: 28.182481738860538\n",
      "7 max c: 0.2086165552898738 max beta: 12.782266811398811\n",
      "8 max c: 0.17106349129467002 max beta: 22.89514350672392\n",
      "9 max c: 0.20227881212440466 max beta: 37.69963964931058\n",
      "10 max c: 0.18599401269209412 max beta: 35.16065740216531\n",
      "11 max c: 0.16354096616373012 max beta: 26.127748522390494\n",
      "12 max c: 0.18620847261848444 max beta: 37.06149598019706\n",
      "13 max c: 0.19392431978849228 max beta: 21.519300521089274\n",
      "14 max c: 0.18908387845325453 max beta: 37.67894972606554\n",
      "15 max c: 0.17236043183357913 max beta: 32.033048900971146\n",
      "16 max c: 0.20037958447032414 max beta: 33.50868099946293\n",
      "17 max c: 0.19662475034969404 max beta: 36.551111027407956\n",
      "18 max c: 0.1764125850721212 max beta: 21.72133111581879\n",
      "19 max c: 0.18568049465394476 max beta: 29.798303966562006\n",
      "20 max c: 0.20546675112887652 max beta: 31.652572288891445\n",
      "21 max c: 0.18845729842314768 max beta: 23.63221293205236\n",
      "22 max c: 0.20510787586278684 max beta: 36.822850208745486\n",
      "23 max c: 0.20315277647631705 max beta: 19.287158285816535\n",
      "24 max c: 0.1961697775784039 max beta: 24.090685174385634\n",
      "25 max c: 0.2059110089871474 max beta: 18.792918483813388\n",
      "26 max c: 0.2129268780423378 max beta: 23.1799880617931\n",
      "27 max c: 0.20174008498439552 max beta: 29.363272543885937\n",
      "28 max c: 0.1936649737662936 max beta: 36.864328086956405\n",
      "29 max c: 0.21339217346309297 max beta: 31.762177935303264\n",
      "30 max c: 0.17665779716737676 max beta: 26.894449691462817\n",
      "31 max c: 0.20092387381505433 max beta: 28.46860248350903\n"
     ]
    }
   ],
   "source": [
    "mean_mesh = np.mean(base_meshs,0)\n",
    "base_mesh = torch.from_numpy(mean_mesh)\n",
    "\n",
    "p1 = generate_process(batch_size=32, noise_size=noise_dim,mesh2num=mesh2num,upper=upper_vdim,device='cpu')\n",
    "\n",
    "p2 = process2(p1,mesh2num_model,G,D)\n",
    "\n",
    "fake_ffdpca = p2.sample(base_mesh,64,pic_path)\n",
    "np.save(pic_path + 'complicated_ffdpca',fake_ffdpca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDOE import lhs\n",
    "\n",
    "BATCH_SIZE = 4452\n",
    "p = 100\n",
    "a = np.array(lhs(1,p) * BATCH_SIZE,dtype=int)[:,0]\n",
    "base_plot = base_meshs[a]\n",
    "np.save( pic_path+'base_meshs', base_plot)\n",
    "min_batch = 10\n",
    "base_plots = torch.from_numpy(base_plot)\n",
    "fake_ffdpcas = []\n",
    "for i in range(p):\n",
    "    base_mesh = base_plots[i]\n",
    "    p1 = generate_process(batch_size=min_batch, noise_size=noise_dim,mesh2num=mesh2num,upper=upper_vdim,device=device)\n",
    "    p2 = process2(p1,mesh2num_model,G,D)\n",
    "    fake_ffdpca = p2.sample(base_mesh,min_batch,pic_path,False)\n",
    "    fake_ffdpcas.append(fake_ffdpca)\n",
    "\n",
    "fake_ffdpcas = np.array(fake_ffdpcas)\n",
    "np.save(pic_path + 'complicated_ffdpca',fake_ffdpcas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试连续生成"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# easy的生成测试\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path3   = 'result/last_result_easy/'\n",
    "pic_path     = 'result/test_pic/'\n",
    "noise_dim  = 8\n",
    "mesh2num   = 8\n",
    "BATCH_SIZE = 256\n",
    "batch_size = BATCH_SIZE\n",
    "ffd_dim    = (3,7,1)\n",
    "point_num  = (ffd_dim[0]+1)*(ffd_dim[1]+1)*(ffd_dim[2]+1)\n",
    "dim_mesh   = (18,68,3)\n",
    "upper_vdim = 64\n",
    "lower_vdim = 11\n",
    "device = 'cpu'\n",
    "\n",
    "mesh2num_model = model.ConvNet(mesh2num).to(device) \n",
    "G = model.DeepConvNet_easy2(noise_dim,point_num,upper_vdim).to(device)\n",
    "D = model.DeepConvNet2(batch_size,1).to(device) #输出为1维向量\n",
    "\n",
    "mesh2num_model.load_state_dict(torch.load(save_path3 +\"m2n_param.pkl\"))\n",
    "G.load_state_dict(torch.load(save_path3 +\"generator_param.pkl\"))\n",
    "D.load_state_dict(torch.load(save_path3 +\"discriminator_param.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = generate_process(batch_size=256, noise_size=noise_dim,mesh2num=mesh2num,upper=upper_vdim,device=device)\n",
    "\n",
    "p2 = process2(p1,mesh2num_model,G,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 18, 68, 3)\n"
     ]
    }
   ],
   "source": [
    "data_root   = 'F:\\\\graduate_student\\\\T2_GANpropeller\\\\test5\\\\0_database\\\\mixed_model\\\\'\n",
    "\n",
    "geom_list = np.load(data_root + 'easy_real.npy')\n",
    "base_mesh = torch.from_numpy(np.mean(geom_list,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "easy_ffdpca =   p2.easy_sample(base_mesh,pic_path,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = []\n",
    "for i in easy_ffdpca:\n",
    "    bottle = i[0,:,:]\n",
    "    center = np.mean(bottle,0)\n",
    "    p.append(i - center)\n",
    "p = np.array(p)\n",
    "np.save('result/test_pic/fake_mesh2',p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 18, 68, 3)\n"
     ]
    }
   ],
   "source": [
    "a = np.load('result/test_pic/fake_mesh0.npy')\n",
    "b = np.load('result/test_pic/fake_mesh1.npy')\n",
    "c = np.load('result/test_pic/fake_mesh2.npy')\n",
    "\n",
    "data  = np.concatenate((a,b,c),0)\n",
    "print(data.shape)\n",
    "np.save('result/test_pic/fake_mesh.npy',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成顺序[1,2,5,7,9],[8,16,32,64]\n",
    "\n",
    "def get_easy_result(save_path3,noise_dim,save_path,batch_size,base_meshs):\n",
    "\n",
    "    ffd_dim    = (3,7,1)\n",
    "    point_num  = (ffd_dim[0]+1)*(ffd_dim[1]+1)*(ffd_dim[2]+1)\n",
    "    dim_mesh   = (18,68,3)\n",
    "    upper_vdim = 64\n",
    "    lower_vdim = 11\n",
    "    device = 'cpu'\n",
    "    mesh2num = noise_dim\n",
    "    mesh2num_model = model.ConvNet(mesh2num).to(device) \n",
    "    G = model.DeepConvNet_easy2(noise_dim+mesh2num,point_num,upper_vdim).to(device)\n",
    "    D = model.DeepConvNet2(batch_size,1).to(device) #输出为1维向量\n",
    "\n",
    "    mesh2num_model.load_state_dict(torch.load(save_path3 +\"/m2n_param.pkl\"))\n",
    "    G.load_state_dict(torch.load(save_path3 +\"/generator_param.pkl\"))\n",
    "    D.load_state_dict(torch.load(save_path3 +\"/discriminator_param.pkl\"))\n",
    "\n",
    "    p1 = generate_process(batch_size=batch_size//base_meshs.shape[0], noise_size=noise_dim,mesh2num=mesh2num,upper=upper_vdim,device=device)\n",
    "\n",
    "    p2 = process2(p1,mesh2num_model,G,D)\n",
    "    easy_ffdpcas = []\n",
    "    for base_mesh in base_meshs: \n",
    "        easy_ffdpca =   p2.easy_sample(base_mesh,pic_path,False)\n",
    "        easy_ffdpcas.append(easy_ffdpca)\n",
    "    \n",
    "    easy_ffdpcas = np.array(easy_ffdpcas)\n",
    "    easy_ffdpcas = easy_ffdpcas.reshape(-1,18,68,3)\n",
    "    np.save(save_path,easy_ffdpcas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list1 = ['base1','base2','base3','base5','base7','base9']\n",
    "noise_num1  = [8,16,16,16,16,16]\n",
    "name_list2 = ['easy8','easy16','easy32','easy64']\n",
    "noise_num2  = [8,16,32,64]\n",
    "base_list  = [ [1500],\n",
    "                [700,2300],\n",
    "                [500,1500,2500],\n",
    "                [500,1200,1500,1700,2500],\n",
    "                [300,700,1200,1500,1700,2300,2500],\n",
    "                [300,500,700,1200,1500,1700,2300,2500,2700]]\n",
    "\n",
    "def get_base_meshs(base_po,geom_list):\n",
    "    \n",
    "    base_meshs = []\n",
    "    for i in base_po:\n",
    "        base_meshs.append(geom_list[i])\n",
    "    base_meshs = torch.from_numpy(np.array(base_meshs))\n",
    "    return base_meshs\n",
    "\n",
    "save_path_list1  = ['result/test_pic/'+_ for _ in name_list1]\n",
    "save_path_list2  = ['result/test_pic/'+_ for _ in name_list2]\n",
    "\n",
    "name_list1 = ['result/last_result_'+ _ for _ in name_list1]\n",
    "name_list2 = ['result/last_result_'+ _ for _ in name_list2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(name_list1)):\n",
    "    name = name_list1[i]\n",
    "    base_meshs = get_base_meshs(base_list[i],geom_list)\n",
    "    get_easy_result(name_list1[i],noise_num1[i],save_path_list1[i],512,base_meshs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(name_list2)):\n",
    "    name = name_list2[i]\n",
    "    print(i)\n",
    "    base_meshs = get_base_meshs([500,1500,2500],geom_list)\n",
    "    get_easy_result(name_list2[i],noise_num2[i],save_path_list2[i],512,base_meshs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def easy_surface(foil_data,ax, path = ''):\n",
    "    # p = foil_data\n",
    "    foil_data = foil_data.reshape(-1,3)\n",
    "    x = foil_data[:,0]\n",
    "    y = foil_data[:,1]\n",
    "    z = foil_data[:,2]\n",
    "\n",
    "\n",
    "    # ax.set_xlim(0,1)\n",
    "    # ax.set_ylim(-0.5,0.5)\n",
    "    # ax.set_zlim(-0.5,0.5)\n",
    "\n",
    "    # ax.plot_surface(x,y,z,rstride = 1,cstride = 1, cmap= 'gist_yarg',alpha = 0.3)\n",
    "    ax.scatter3D(x,y,z,s=0.5,alpha = 0.1,c='b')\n",
    "    return ax\n",
    "\n",
    "def get_meshcloud(new_meshs,save_path,num  = 100):\n",
    "\n",
    "    posi =random.sample(range(1,new_meshs.shape[0]),num)\n",
    "    new_meshs = new_meshs[posi]\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    ax = plt.axes(projection=\"3d\")\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)\n",
    "    ax.zaxis.set_visible(False)\n",
    "    for i in new_meshs:\n",
    "        ax = easy_surface(i,ax)\n",
    "\n",
    "    ax.view_init(elev=75, azim=0)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 18, 68, 3)\n",
      "(512, 18, 68, 3)\n",
      "(510, 18, 68, 3)\n",
      "(510, 18, 68, 3)\n",
      "(511, 18, 68, 3)\n",
      "(504, 18, 68, 3)\n"
     ]
    }
   ],
   "source": [
    "for i in save_path_list1:\n",
    "    tmp = np.load(i + '.npy')\n",
    "    print(tmp.shape)\n",
    "    get_meshcloud(tmp,i + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(510, 18, 68, 3)\n",
      "(510, 18, 68, 3)\n",
      "(510, 18, 68, 3)\n",
      "(510, 18, 68, 3)\n"
     ]
    }
   ],
   "source": [
    "for i in save_path_list2:\n",
    "    tmp = np.load(i + '.npy')\n",
    "    print(tmp.shape)\n",
    "    get_meshcloud(tmp,i + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_meshcloud(geom_list,'result/test_pic/real.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4c931384c189ae75f8be27cf3a476a73e5601e0430a23822067a21f7d017973"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
